{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBHQ8C_ii4uk"
      },
      "source": [
        "# Information extraction examples\n",
        "\n",
        "This notebook demonstrates information extraction examples using Spacy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptbD2wvWi4uo"
      },
      "source": [
        "import re\n",
        "from IPython.display import display, HTML\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "# normally: nlp = spacy.load('en_core_web_sm')\n",
        "nlp = spacy.load('./.local/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-2.2.5') # Jupyterhub location"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1ff6bLci4ut"
      },
      "source": [
        "doc = \"Barack Obama was born in Hawaii on 4th of August, 1961.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "660Xkfr0i4ux"
      },
      "source": [
        "text = nlp(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwUgw33ui4u3"
      },
      "source": [
        "for token in text.doc:\n",
        "    print(token.text, token.i) # tokenised; i provides an index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srU1ZV6ji4u9"
      },
      "source": [
        "# tokenise by sentences\n",
        "\n",
        "for sentence in text.sents:\n",
        "    print(sentence, sentence.start, sentence.end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPUDJ4yWi4vA"
      },
      "source": [
        "# obtain parts of speech with Penn Treebank tags\n",
        "\n",
        "for token in text:\n",
        "    print(token, token.tag_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFjxyHDni4vH"
      },
      "source": [
        "# filter by part of speech\n",
        "\n",
        "for token in text:\n",
        "    if token.tag_ == 'NNP':\n",
        "        print(token, token.i, token.idx) # i = token index; idx = character index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty-Dk6kwi4vM"
      },
      "source": [
        "# extract entities\n",
        "text.ents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRQ7UG7Ci4vT"
      },
      "source": [
        "# iterate over entities and print labels, start & end indices\n",
        "\n",
        "for ent in text.ents:\n",
        "    print(ent.text, ent.label_, ent.start, ent.end)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzVsjdGBi4va"
      },
      "source": [
        "# NZ specific locations - Māori place names\n",
        "\n",
        "location_example = '''Porritt Park, an old loop of the Avon River, lies within Wainoni. Going clockwise from there, \n",
        "                    boundary roads of the suburb are Wainoni, Breezes, Pages, and Kerrs Roads. \n",
        "                    Wainoni is approximately 7 kilometres (4.3 mi) from the central city. \n",
        "                    Wainoni Park is located in the adjacent suburb of Aranui.\n",
        "                    Wainoni and its neighbouring suburb of Aranui are often considered together and intermixed. \n",
        "                    For example, Wainoni School and Wainoni Park are located in Aranui, and Aranui High School \n",
        "                    is located in Wainoni. Christchurch City Council publishes a combined community profile for \n",
        "                    the two suburbs. '''\n",
        "\n",
        "loc_text = nlp(location_example)\n",
        "\n",
        "for ent in loc_text.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mioTHtbci4ve"
      },
      "source": [
        "# another example text\n",
        "\n",
        "doc_with_nouns = '''The UK will be hit with a three-month meltdown at its ports, a hard Irish border and shortages of food and medicine if it leaves the EU without a deal, according to government documents on Operation Yellowhammer.'''\n",
        "\n",
        "text2 = nlp(doc_with_nouns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9o3BTcki4vq"
      },
      "source": [
        "# GPE = Geopolitical Entities\n",
        "# NORP = Nationality, Religious or Political organisations\n",
        "# ORG = Organisation\n",
        "\n",
        "for ent in text2.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOsC08wci4vu"
      },
      "source": [
        "# The displacy module visualises these entities nicely\n",
        "displacy.render(text2, style='ent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDVshfU7i4vx"
      },
      "source": [
        "# extract noun phrases (noun chunks)\n",
        "\n",
        "for chunk in text2.noun_chunks:\n",
        "    print(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2hFhWuhi4vz"
      },
      "source": [
        "# Dependency parsing\n",
        "# For interest: syntactic dependencies are described here - https://universaldependencies.org/docs/en/dep/\n",
        "\n",
        "for token in text:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "            [child for child in token.children])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6IRHBUHi4v2"
      },
      "source": [
        "displacy.render(text, style='dep')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZGBhS8qi4v5"
      },
      "source": [
        "### Relation Extraction\n",
        "\n",
        "Below is an example script taken directly from [https://spacy.io/usage/examples](https://spacy.io/usage/examples)\n",
        "\n",
        "It finds the relationship between MONEY entities and the noun phrases they relate to in these two sentences:\n",
        "\n",
        "```\"Net income was $9.4 million compared to the prior year of $2.7 million. Revenue exceeded twelve billion dollars, with a loss of $1b.\"```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDIdT8XDi4v-"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf8\n",
        "\"\"\"A simple example of extracting relations between phrases and entities using\n",
        "spaCy's named entity recognizer and the dependency parse. Here, we extract\n",
        "money and currency values (entities labelled as MONEY) and then check the\n",
        "dependency tree to find the noun phrase they are referring to – for example:\n",
        "$9.4 million --> Net income.\n",
        "\n",
        "Compatible with: spaCy v2.0.0+\n",
        "Last tested with: v2.2.1\n",
        "\"\"\"\n",
        "from __future__ import unicode_literals, print_function\n",
        "\n",
        "import plac\n",
        "import spacy\n",
        "\n",
        "\n",
        "TEXTS = [\n",
        "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
        "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
        "]\n",
        "\n",
        "\n",
        "@plac.annotations(\n",
        "    model=(\"Model to load (needs parser and NER)\", \"positional\", None, str)\n",
        ")\n",
        "def main(model=\"en_core_web_sm\"):\n",
        "    nlp = spacy.load(model)\n",
        "    print(\"Loaded model '%s'\" % model)\n",
        "    print(\"Processing %d texts\" % len(TEXTS))\n",
        "\n",
        "    for text in TEXTS:\n",
        "        doc = nlp(text)\n",
        "        relations = extract_currency_relations(doc)\n",
        "        for r1, r2 in relations:\n",
        "            print(\"{:<10}\\t{}\\t{}\".format(r1.text, r2.ent_type_, r2.text))\n",
        "\n",
        "\n",
        "def filter_spans(spans):\n",
        "    # Filter a sequence of spans so they don't contain overlaps\n",
        "    # For spaCy 2.1.4+: this function is available as spacy.util.filter_spans()\n",
        "    get_sort_key = lambda span: (span.end - span.start, -span.start)\n",
        "    sorted_spans = sorted(spans, key=get_sort_key, reverse=True)\n",
        "    result = []\n",
        "    seen_tokens = set()\n",
        "    for span in sorted_spans:\n",
        "        # Check for end - 1 here because boundaries are inclusive\n",
        "        if span.start not in seen_tokens and span.end - 1 not in seen_tokens:\n",
        "            result.append(span)\n",
        "        seen_tokens.update(range(span.start, span.end))\n",
        "    result = sorted(result, key=lambda span: span.start)\n",
        "    return result\n",
        "\n",
        "\n",
        "def extract_currency_relations(doc):\n",
        "    # Merge entities and noun chunks into one token\n",
        "    spans = list(doc.ents) + list(doc.noun_chunks)\n",
        "    spans = filter_spans(spans)\n",
        "    with doc.retokenize() as retokenizer:\n",
        "        for span in spans:\n",
        "            retokenizer.merge(span)\n",
        "\n",
        "    relations = []\n",
        "    for money in filter(lambda w: w.ent_type_ == \"MONEY\", doc):\n",
        "        if money.dep_ in (\"attr\", \"dobj\"):\n",
        "            subject = [w for w in money.head.lefts if w.dep_ == \"nsubj\"]\n",
        "            if subject:\n",
        "                subject = subject[0]\n",
        "                relations.append((subject, money))\n",
        "        elif money.dep_ == \"pobj\" and money.head.dep_ == \"prep\":\n",
        "            relations.append((money.head.head, money))\n",
        "    return relations\n",
        "\n",
        "main()\n",
        "\n",
        "    # Expected output:\n",
        "    # Net income      MONEY   $9.4 million\n",
        "    # the prior year  MONEY   $2.7 million\n",
        "    # Revenue         MONEY   twelve billion dollars\n",
        "    # a loss          MONEY   1b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyBSbU8Ti4wC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}